{
  "cells": [
    {
      "metadata": {
        "_uuid": "fd7673ae720acd431bb25953b6a476c4caf981b7",
        "_cell_guid": "3bf23366-bbc4-43a1-a080-a67b1997f282"
      },
      "cell_type": "markdown",
      "source": "# Who Lives? Who Dies? You Decide! #\n## (Actually no, a model will, but you get my drift) ##\n### Tammy Rotem #### \n\nThanking [Megan Risdal](https://www.kaggle.com/mrisdal/exploring-survival-on-the-titanic) for her great work with Titanic Survival, which inspired this notebook.\n\n1. [Introduction](#introduction) <br/>\n    1.1 [Load packages and check data](#loading) <br/>\n2. [Feature Engineering](#featureeng)<br/> \n    2.1 [Passenger Name](#featurename) <br/>\n    2.2 [Reduce Title to Mr., Mrs., Miss. and Master](#title_reduce)<br/>\n    2.3 [How many relatives a passenger has on board?](#famsize)<br/>\n3. [Handle Missing Values](#missing_values) <br/>\n    3.1 [ Missing Fare Values](#fare)<br/>\n    3.2 [Missing Embarked Values](#embarked)<br/>\n    3.3 [Missing Age Values](#age)<br/>\n4. [Predictive Modeling](#modeling)<br/>\n    4.1 [Encode categorical variables](#encode)<br/>\n    4.2 [Training random forest classifier](#training)<br/>\n5. [Submit predicted results](#results)<br/>\n\n"
    },
    {
      "metadata": {
        "_uuid": "0668b6055f4301bfc418084f4b14aac768f6b3f3",
        "_cell_guid": "4437ae60-b0b8-4094-8a25-12f18fe71a26"
      },
      "cell_type": "markdown",
      "source": " # 1 Introduction <a class=\"anchor\" id=\"introduction\"></a>\n This is my first competition submission and I'm super excited about it. I really loved what Megan did with this dataset using R, so I thought I should try doing the same with Python. The reason for this is I've been working with R quite a lot in the past few years and I want to be as proficient in Python (First Python notebook!).\n \n> In addition, I will try to do things the way I think they should be done in a near production environment - meaning, all manipulations on training data are designed in functions which in reality will be applied to any new data awaiting prediction.\n \n So here I go!"
    },
    {
      "metadata": {
        "_uuid": "1755550cc13f01dfd7ec26aa424c77d0285a2cb8",
        "_cell_guid": "733f344d-99b1-4772-93cb-14bad34e4b49"
      },
      "cell_type": "markdown",
      "source": " ## 1.1 Load packages and check data <a class=\"anchor\" id=\"section1\"></a>\n"
    },
    {
      "metadata": {
        "_uuid": "5467587ac0f1871cda8f4538c8a3a6aec643f69b",
        "_cell_guid": "0298144b-2553-45a1-9937-fd9af4a838e9",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "import numpy as np # linear algebra\nimport pandas as pd # data processing\nimport seaborn as sns #visualisation\nimport matplotlib.pyplot as plt #visualisation\nfrom sklearn.ensemble import RandomForestClassifier #Classification by trees ensemble",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4baa975aa28fe6f3190e6a026b9e691e41632f28",
        "_cell_guid": "871995d7-ea5d-4ab9-9110-64e8ac69188f"
      },
      "cell_type": "markdown",
      "source": "Now that our packages our loaded, let's get the data. I'll load the training and test sets each on its own.\n\nIn addition, I will combine both datasets so I can perform feature engineering properly. \nWhat I mean is: If I'm tranforming a Nominal column (like Embarked or Ticket), and only looking at the training set - there may be values in the testing set that I didn't know about or seen before - so I won't know how to transform them before executing a predictive model.\n\nIn reality - this is a tricky question - how to transform previously unknown values correctly? When maintaining a model - a lot of attention should be given to all the data that passes through it so It will be handled in the best way. If new values are found in the future - they should be added to the transformation process. **This is the reason why I combine the training and testing sets for feature engineering.**\n\n"
    },
    {
      "metadata": {
        "_uuid": "a78cddada51fe7d5b95f7b55b9ab19297f607215",
        "_cell_guid": "6f643e12-b7d4-49a4-a9b0-c3337f4c0b9d",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train=pd.read_csv(\"../input/train.csv\")\ntest=pd.read_csv(\"../input/test.csv\")\n#Function to append sets with an idetifying partition field for later seperation or other uses\ndef append_train_test(train,test): \n    train[\"IsTrain\"]=1\n    test[\"IsTrain\"]=0\n    df=train.append(test)\n    return df;\n\nfull=append_train_test(train,test)\n\ntrain.info()\nprint (\"------------------------\")\ntest.info()\nprint (\"------------------------\")\nfull.info()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "cf381c12c235f814e892dc7add27affd92c36c16",
        "_cell_guid": "dc9cdda9-9014-40d4-8560-1d834eed3c33"
      },
      "cell_type": "markdown",
      "source": "We notice we have some missing values we should fill (Age & Cabin). Let's look at some examples of the records (the full dataset is a good place to look). At this point we know our data pretty well, the variables we have and their types - so we can move on to feature engineering."
    },
    {
      "metadata": {
        "_uuid": "f71952d555a446558c1259972a6051d3fd84e5aa",
        "_cell_guid": "38508815-fe75-4c0d-8636-2a1bc55f5345",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "full.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "41ee6b0d91548615c01d84f88c663b8786a6efaa",
        "_cell_guid": "4020a19a-0356-46db-93b0-775a682c8dc6"
      },
      "cell_type": "markdown",
      "source": "# 2 Feature Engineering <a class=\"anchor\" id=\"featureeng\"></a>\nThis part is dedicated to data enrichment by creating some new variables. This step is important becuase the set of variables we got with the dataset may not be the best seperators of survival. Deriving new variables from the given set may prove to be better seperators.\n\n## 2.1 Get the honorary title from Name column <a class=\"anchor\" id=\"namefeature\"></a>\nWhat we intend to achieve here is to get more variables out of passenger name. Why? Using the  name in our model will be a lot like using a passenger's id - each passenger has an almost unique value. Instead, we want to look at passeger similarity (or difference) at a higher level. In this case, the honorary **title**  helps group similar passengers, and this title is present in the **name** variable. \n\nI'll use regular expressions to extract substrings which end with a dot (e.g. Miss., Master., etc.) from the Name column. I'll put this result into a new column named \"Title\". The regex I use aims to match a group of words which can be any alphanumeric combination which ends with a dot. I'll be writing this as a custom function, becuase in reality this would be applied to any new data in need of prediction.\n\nAfter I create the new variable **Title** I look at all available values and their counts.\n\n"
    },
    {
      "metadata": {
        "_uuid": "2e26d2dddc83b11801d30dc57a2a2aa0257a2aeb",
        "_cell_guid": "1ccd2803-443c-461b-85c1-5be5a5efe215",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#remember that \\w is equivalent to [A-Za-z] all alphanumeric chars, dot must be escaped with \"\\\" \n#and a match group (like the word) is enclosed in \"()\", the + is a quantifier meaning one or more of \\w.\ndef get_title(df,name_column,new_column): #call function example: get_title(train,\"Name\",\"Title\")\n    df[new_column] = df[name_column].str.extract('(\\w+)\\.', expand=True)\n    return df;\n#I then pass the entire dataset to the function to generate the Title column for all the records\nget_title(full,\"Name\",\"Title\")\nfull.Title.value_counts() #Looks at all available values and their counts",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "156ac8e57664342251337e58a148b4b04a59b5c7",
        "_cell_guid": "709d47d8-114b-4ccd-b64e-f92fcd436df8"
      },
      "cell_type": "markdown",
      "source": "Once we look at the values we can see that several values are incredibly rare, such as \"Don\" or \"Mme\". Leaving this column the way it is will result in a possbile loss of information. Even though there are very little records with these \"rare\" titles - we don't know how many will be in the test set. So, let's get these in order.\n\nTime to find equivalence in these titles! According to Wikipedia:<br/>\nMme = \"Medame\" = Mrs <br/>\nMlle = \"Mademoiselle\" = Miss <br/>\nMs = \"Miz\" = Miss <br/>\n\nIn addition, wikipedia teaches us that other titles in this list refer to nobility (from different nationalities) such as: Sir, Lady, Countess and more. Other titles, are military titles such as Col, Major and Capt. There are also other proffesionals like Dr and Reverend.\n\nFinally, I want the **Title** variable to be reduced to only Mr.,Mrs.,Miss. and Master. In many cases I would like to indicate for certain cases if they have special titles (like nobility or military) but these are so low in frequency - it is redundant.\n\n## 2.2 Reduce title to Mr., Mrs., Miss. and Master <a class=\"anchor\" id=\"title_reduce\"></a>\nSome assumptions: Reverends are all men right? How about Doctors? Colonels, Majors, Captains? Let's check this out:"
    },
    {
      "metadata": {
        "_uuid": "14f275c9f765f0cdafec1015a8cfc4d0f9b8b8b6",
        "_cell_guid": "6d4b9b33-dcf3-4dc5-9873-495b395844bc",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "full.loc[(full[\"Title\"].isin([\"Rev\",\"Dr\",\"Col\",\"Capt\",\"Major\"])) & (full[\"Sex\"]!=\"male\")]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8743e8eadc05e788fce744d4f150d4a171178d3e",
        "_cell_guid": "b05480a1-07fa-4459-b920-3569e8374125"
      },
      "cell_type": "markdown",
      "source": "Well, looks like we have a female doctor on board - and in fact she was a survivor! So, now when we re-encode these titles we will encode with respect to sex as well. If we think about passengers in this day and age - we could have military officials who are females.\n\nWe'll start with a new column with null values, called Reduced_Title, into which we can re-encode all titles to just Mr, Mrs, Miss and Master."
    },
    {
      "metadata": {
        "_uuid": "0c818e14c142f33a90f6037654908c4d29183e86",
        "_cell_guid": "23d9b446-85bb-4405-8289-37f8947c6377",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "full.loc[(full[\"Title\"].isin([\"Rev\",\"Capt\",\"Major\",\"Col\",\"Jonkheer\",\"Don\",\"Sir\",\"Dr\"])) & (full[\"Sex\"]==\"male\"),\"Title\"] = \"Mr\"\nfull.loc[(full[\"Title\"].isin([\"Countess\",\"Lady\",\"Dona\",\"Mme\"])),\"Title\"]=\"Mrs\"\nfull.loc[(full[\"Title\"].isin([\"Mlle\",\"Ms\",\"Dr\"])) & (full[\"Sex\"]==\"female\"),\"Title\"]=\"Miss\"\n\nfull[\"Title\"].value_counts(normalize=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "42dd32f9fdd998f7ec512bd170f9c88a29888009",
        "_cell_guid": "83d6f23c-1395-4eb1-a391-9c039244c187"
      },
      "cell_type": "markdown",
      "source": "Now we have a new nominal variable **Title** with a pretty good distribution of values (~59%, 20%,15%,4%). All categories are represented pretty well. This is a good time to see the relationship between this new variable and sruvival."
    },
    {
      "metadata": {
        "_uuid": "a537562b41ea3866369ac615c4da1970b96c5342",
        "_cell_guid": "100f5c43-976e-4b90-ba2d-637f81f2c67e",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "sns.countplot('Title',hue='Survived',data=full.iloc[:891])\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "931a8cb440d8df432f4b810681b2caf64a73c6df",
        "_cell_guid": "9afc5c3d-3c2a-4b56-b66f-8f1824403665"
      },
      "cell_type": "markdown",
      "source": "Now we know for sure that the \"women and children first\" policy was indeed enacted on board the Titanic. Women (Especially married women, maybe mothers) have a better chance to survive, so do children. This is evident becuase only the \"Mr\" title group mostly died in the accident.\n## 2.3 How many relatives a passenger has on board? <a class=\"anchor\" id=\"famsize\"></a>\nWe want to use **SibSp** (number of siblings/spouses on board) plus **Parch** (number of parents/children on board) to tell the size of the passenger's family. It is logical to think there is a relationship between family size and survival - having people to look after you, and make sure you get onboard a rescue boat."
    },
    {
      "metadata": {
        "_uuid": "84284686976c78b7d39e75b2e0fc1d9290990c8e",
        "_cell_guid": "7cd45634-188a-4f45-9318-63b741eaab0d",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "full[\"FamilySize\"]=full[\"SibSp\"]+full[\"Parch\"]+1\n\nf,ax=plt.subplots(1,2,figsize=(18,8))\n#Let's look at how family size is connected with Title\nsns.countplot('FamilySize',hue='Title',data=full.iloc[:891],ax=ax[0])\nax[0].set_title('Family Sizs vs Title')\n#Let's look at how survival is distributed along family sizes\nsns.countplot('FamilySize',hue='Survived',data=full.iloc[:891],ax=ax[1])\nax[1].set_title('Family size vs Survived')\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "52d58d52b63bcb6d658209c84f16814a075cb137",
        "_cell_guid": "7459ef43-4628-440f-8f69-f56ed1e55d44"
      },
      "cell_type": "markdown",
      "source": "The left plot tells us that most lone travellers on the Titanic were adult men, after them young/unmarried women. The right plot tells us this group of people has the slightest chance to survive (Travelling alone never sounded worst!) ->These will be our lone travellers.\nFurthermore, only in families of sizes 2,3 and 4 there is a greater chance to survive, when family size is over 4 again there is a smaller chance to survive. Let's describe that in a new **discrete family size variable**\n"
    },
    {
      "metadata": {
        "_uuid": "cd2907130b130dbe3194002b582fbd21e7dab120",
        "_cell_guid": "e4652e56-e9f2-4486-84ff-f95ee3124cec",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "full[\"FamilySizeBand\"]=np.nan\nfull.loc[full[\"FamilySize\"]==1,\"FamilySizeBand\"]=\"Loner\"\nfull.loc[(full[\"FamilySize\"]<5) & (full[\"FamilySize\"]>1),\"FamilySizeBand\"]=\"SmallFam\"\nfull.loc[full[\"FamilySize\"]>4,\"FamilySizeBand\"]=\"BigFam\"\n#Let's look a survival rate within classes and family sizes\nsns.factorplot('FamilySizeBand','Survived',hue='Pclass',col=\"Sex\",data=full.iloc[:891])\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "3c68098bc13f4043244d47db304de97df966a8b9",
        "_cell_guid": "e9ce6c53-be34-49d8-a877-c619efa9b6a9"
      },
      "cell_type": "markdown",
      "source": "Here is an interesting picture - We already know women are way more likely to survive than men, In addition - women are more likely to survive even when they are part of a big family on board, as long as they are from 1st or 2nd class. Men have a better chance to survive if they are part of small families, regardless of class, whilst women would rather be loners (especially from 3rd class) or from big families (and not 3rd class).\n# 3 Handle Missing Values <a class=\"anchor\" id=\"missing_values\"></a>\nWe know we have some missing values we have to take care of before we go further and move to modeling. I would like to start with the \"trivial\" imputation (few missing values which can be handled manually, and then examine ways to impute many missing values)."
    },
    {
      "metadata": {
        "_uuid": "03b69d1383e1e473ff5998faadb548b95b7ce1eb",
        "_cell_guid": "8912c7ac-03dd-4ac8-bf0b-26212d43b001",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "full.isnull().sum()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ea0c7e5c72c2c906addf7209d5f3784251dde294",
        "_cell_guid": "2597d704-731e-42aa-ad85-312551d0f7b8"
      },
      "cell_type": "markdown",
      "source": "Looks like we have **263 missing Age values , 1014 missing Cabin values , 2 missing Embarked values , 1 missing Fare value.**The line that says 418 null \"Survived\" values are'nt really mising - that's the test set.\n## 3.1 Missing Fare Value <a class=\"anchor\" id=\"fare\"></a>\nThe best approach I see to impute a missing continuous value like this one is to see if we can infer the required value from other fetures. Let's start by finding this row in the data:"
    },
    {
      "metadata": {
        "_uuid": "2a4291147b2134fe5ce734380932b27b0cd7f407",
        "_cell_guid": "257603b4-5ddb-436b-83cf-c632e5075c26",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "full[full.Fare.isnull()]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "586bcc3d535856d8dd22e67f3efc29e135ef169d",
        "_cell_guid": "168b2b20-f59e-48c7-a9fe-20ffa939bde8"
      },
      "cell_type": "markdown",
      "source": "We are looking at a loner, who embarked from Southampton, aged 60.5 and is a man from 3rd class. Let's look at the fare distribution of this group of people."
    },
    {
      "metadata": {
        "_uuid": "22252ddef214cb9d21bb9a2c17e13eefd830cc13",
        "_cell_guid": "7318c9c1-83fb-41f1-a693-3cb12350f7c1",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "fare=full[(full.Embarked==\"S\") & (full.Title==\"Mr\") & (full.FamilySizeBand==\"Loner\") & (full.Pclass==3) & (full.Fare.notnull())]\nsns.distplot(fare.Fare)\nfare.Fare.describe() #this gives us the amount of records, and description of distribution",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9d2712d15ae27f9bde1a4e310fda39a2e6029724",
        "_cell_guid": "dc85d656-9aee-4c0f-bb7b-bfbd9205d9dc"
      },
      "cell_type": "markdown",
      "source": "Up to 75% of 277 passengers (i.e 170 and up) paid less or equal to 8 dollars per ticket. I think it is safe to put this missing fare at the 75% quartile, meaning at 8 dollars. It really makes me wonder about these 3rd class passengers who paid over 10$ per ticket! Why? this is extreme behavior! we might want to consider removing extreme values from the Fare variable later on."
    },
    {
      "metadata": {
        "_uuid": "f2fda20d54c01098dca6a0288db72151589987d5",
        "_cell_guid": "e603022e-c03b-4a23-ba14-ae28791ce9ae",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# imputing the missing fare value\nfull.loc[(full.Fare.isnull()),\"Fare\"]=8.05",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a6494c93686b9974a2369570245bb880299643b9",
        "_cell_guid": "63b314a6-7e3a-4baa-ab90-85d77d2a7604"
      },
      "cell_type": "markdown",
      "source": "## 3.2 Missing Embarked Values <a class=\"anchor\" id=\"embarked\"></a>\nNow we need to take a look at out missing embarkment ports. These are two records we're looking for:"
    },
    {
      "metadata": {
        "_uuid": "049d641f17982f2b3c16d0a0d385b1c8c4d5d45f",
        "_cell_guid": "d696b6d0-e0fa-4b53-8663-782d0edfbdc0",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "full[full.Embarked.isnull()]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "fc5f669a2f2dae4f43c1e0345d6d2bf28dff4f3f",
        "_cell_guid": "25aca63a-9cfd-422e-8cb2-8ab979d7d17d"
      },
      "cell_type": "markdown",
      "source": "Very interesting, there are common factors to these passengers with missing embarkment: Both are women (although one is married, the other not neccesarily), both travelling alone, and paid equal fairs for the ticket. In addition, both are from 1st class. It is a good time to look at relationships between embarkment and fare:"
    },
    {
      "metadata": {
        "_uuid": "2770ea5e0a2fb3e378f0760cb46901e77a38e227",
        "_cell_guid": "49849dcd-c9cf-4230-b906-52788a927877",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "sns.boxplot(x=\"Embarked\", y=\"Fare\",hue=\"Sex\",data=full[full.Fare.notnull()])\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "552376f572aa75ae50bbc0af4b16556793dd8d0f",
        "_cell_guid": "66d56fa8-ffe7-410c-8632-0031a51e9fd2"
      },
      "cell_type": "markdown",
      "source": "The question we are asking at this point is: If two women paid 80$ per ticket - from which port did they embark from? If we look at the boxplot above we'll notice that: 1)It is very unlikely that both ambarked from Queensland - both men and women paid very low prices in the overall for these embarkment tickets.\n2) It is possible, but still not likely, that they embarked from Southampton. Prices there are higher but still lower in the overall. \nFinally, it is reasonable to assume these passengers embarked from Cherbourg."
    },
    {
      "metadata": {
        "_uuid": "c7b6d7b02db75b30727251f187ee5f515c65e80a",
        "_cell_guid": "0b78706b-e98d-4b63-b7cf-505a739ca0c7",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "#impute missing Embarked values\nfull.loc[(full.Embarked.isnull()),\"Embarked\"]=\"C\"",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8193e4f6d64ecd45c0c1e80e8f5a9cc446d514a6",
        "_cell_guid": "2f4ed998-2e5d-45de-b30f-235dc60271f3"
      },
      "cell_type": "markdown",
      "source": "## 3.3 Missing Age Values <a class=\"anchor\" id=\"age\"></a>\nWe have a lot of missing age values to impute. I noticed earlier that the **Title** variable can be a good predictor for age. I could just impute with the median age of each title group - or, I could get fancy, and use a little smarter imputation like the [KNN](https://pypi.python.org/pypi/fancyimpute) algorithm used in fancyimpute. I had a few problems getting that to work on my first try - so I figured, might as well go ahead and get a solution - even if it is a simple one.\nSo, the biggest assumption behind this solution (imputing Age by Title) is that the Title is a good predictor for Age. Let's look at that closely: The median age changes quite drastically per title and class."
    },
    {
      "metadata": {
        "_uuid": "fdbac745ac53fd37edb0dbe2ecb8391e6153583b",
        "_cell_guid": "7adf5f11-c988-46e6-b647-7cb33322de05",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "data=full[full.Age.notnull()]\nsns.boxplot(x=\"Title\", y=\"Age\",hue=\"Pclass\",data=data)\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1d7a2b1a9e85d1f524116ff6f50a0011938e96a5",
        "_cell_guid": "1fcee2e1-e8f6-413b-a751-b1e0a675a95b"
      },
      "cell_type": "markdown",
      "source": "For this reason - I want to impute ages according to the median age of the same **Title** and **Pclass** group. The smarter thing to do would be to use a regression model or the [fancyimpute](https://pypi.python.org/pypi/fancyimpute/0.0.4) package. In this case I will stick to this kind of imputation (this being my first go at python). I'll just calculate the median age for each Title-Pclass combination"
    },
    {
      "metadata": {
        "_uuid": "2d0d8bc617797bef5235ea9a15c22bcb557ca378",
        "_cell_guid": "cc7d1420-ca46-4698-9b4c-0a610e2ee8ab",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "ImpAge=pd.DataFrame({'median' : data.groupby( [ \"Title\", \"Pclass\"] ).Age.median()}).reset_index()\nImpAge.head(n=20)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9acb9d99274158d3ab0ce02ba0000d40a7c27d33",
        "_cell_guid": "e6877459-8e33-4d0d-8550-e3c7d66f3cfa",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#now we define a function to impute according to these conditions\ndef imputeAges(df):\n    classes=[1,2,3]\n    titles=[\"Mr\",\"Mrs\",\"Miss\",\"Master\"]\n    for title in titles:\n        for pclass in classes:\n            x=ImpAge[((ImpAge.Title==title) & (ImpAge.Pclass==pclass))][\"median\"].values[0]\n            df.loc[((df.Title==title) & (df.Pclass==pclass) & (df.Age.isnull())),\"Age\"]=x\n    return df\nimputeAges(full)\nfull.isnull().sum()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1dbae65ea22d631c4c4ed6ab596772f409518855",
        "_cell_guid": "5272317f-4789-4022-8322-c05714fb61fb"
      },
      "cell_type": "markdown",
      "source": "Ok looks like we are finally done with missing values! The missing cabin values are way too many and I can't picture what can be derived from the cabin number. So, we are gonna drop the **cabin** variable just before we start training models."
    },
    {
      "metadata": {
        "_uuid": "dc38bb4eb6de4bda02194ebf9f0fa0cf82d37dcd",
        "_cell_guid": "b744c8e1-7a8a-428d-b550-5e5ff59c7ba4"
      },
      "cell_type": "markdown",
      "source": "# 4 Predictive Modeling <a class=\"anchor\" id=\"modeling\"></a>\n## 4.1 Encode categorical variables <a class=\"anchor\" id=\"encode\"></a>\nIn order to get all our data in a classifier - we need to convert all categoric features to numeric features.\nI'll do this with the replace function and just convert to numeric values. Instead, I could have created dummy variables with a binary indication for each feature."
    },
    {
      "metadata": {
        "_uuid": "812633d289abd13b6690a5020052d672b2bfa416",
        "_cell_guid": "4ab883a2-a445-49e7-b7ab-2b7e77f12af3",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "full['Sex'].replace(['male','female'],[0,1],inplace=True)\nfull['Embarked'].replace(['S','C','Q'],[0,1,2],inplace=True)\nfull['Title'].replace(['Mr','Mrs','Miss','Master'],[0,1,2,3],inplace=True)\nfull['FamilySizeBand'].replace(['Loner',\"BigFam\",\"SmallFam\"],[0,1,2],inplace=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "6bcdae11c18956e6cca97bd2c199d5eb9ee39b2b",
        "_cell_guid": "f1a87974-62a7-4490-8e9c-d6fc11c9abfe",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "features=[\"Age\",\"Embarked\",\"Fare\",\"Parch\",\"Pclass\",\"Sex\",\"SibSp\",\"Title\",\"FamilySize\",\"FamilySizeBand\"]\ntarget=\"Survived\"\nfull[features].head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "945f146fe82459c3b5d70243978e6d5a59a2813c",
        "_cell_guid": "fa3c085e-4a80-4d66-a1e5-1caaed571d25"
      },
      "cell_type": "markdown",
      "source": "Now it's time to seperate our train and test sets before modeling."
    },
    {
      "metadata": {
        "_uuid": "8a5ded7780c5992c649f1e37bf2dcc27493db83d",
        "_cell_guid": "18617e36-9214-4578-b095-ef464e917c64",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train_features=full[:891][features]\ntrain_target=full[:891][\"Survived\"]\ntest_features=full[891:][features]\ntrain_features.info()\nprint (\"------------------------\")\ntest_features.info()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2c6a9e836dd1152f8f215f3857d780303563f155",
        "_cell_guid": "210a9016-9f9d-4348-a3bf-ffeb5f6653f3"
      },
      "cell_type": "markdown",
      "source": "## 4.2 Training Random Forest classifier <a class=\"anchor\" id=\"training\"></a>\nI am going to train a random forest classifer with a minimum of 15 samples per end leaf."
    },
    {
      "metadata": {
        "_uuid": "06e195b7bd61cbdb96899d68cd515dc7e92f43bc",
        "_cell_guid": "ef8c7be1-fa09-4177-bccf-2234822ee72b",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "clf = RandomForestClassifier(n_jobs=2, random_state=0)\nclf = clf.fit(train_features, train_target)\ntrain_preds=clf.predict(train_features)\nprint (clf)\n## variable importance\n\nfor i in range(0,10):\n        print (features[i],\"       \",clf.feature_importances_[i])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8b6603af1f6d81f7fb9118a63c3053ca203eb738",
        "_cell_guid": "50947ab8-b98c-4e7a-bf8a-8d29b054b727",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Create confusion matrix to evaluate training\npd.crosstab(train_target, train_preds, rownames=['Actual Outcome'], colnames=['Predicted Outcome'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a276b184b035f1af581fcd0df02f1c9788d085da",
        "_cell_guid": "f755b9df-39b9-4503-a0b9-fef7657e42da"
      },
      "cell_type": "markdown",
      "source": "A quick computation tells us the accuracy of training was => 96.6% I hope this would yield an accuracy of around 80% on test.\nTime to find out!\n# 5 Submit predicted results <a class=\"anchor\" id=\"results\"></a>"
    },
    {
      "metadata": {
        "_uuid": "59d4ced38ae89f387eb3c6ee260acce4db21d149",
        "_cell_guid": "9f0ec6af-9e22-40cf-8988-b5833fec4c96",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "test_preds=clf.predict(test_features).astype(int)\ntest_ids=full[891:][\"PassengerId\"]\n\nfinal = pd.DataFrame({\n        \"PassengerId\": test_ids,\n        \"Survived\": test_preds\n    })\n\nfinal.info()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "942cf2c503525f635f8913a1973ee4992ea4b2b9",
        "_cell_guid": "79f0d7cb-0589-4c8d-ad73-3c9edf86cc11",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "final.to_csv('submission2.csv', index=False)",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.3",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}